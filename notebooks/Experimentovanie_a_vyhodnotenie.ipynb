{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentovanie a vyhodnocovanie\n",
    "\n",
    "Miroslav Čulík a Andrej Gáfrik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODOs:\n",
    "- prekopčiť veci z minulých správ do finálnej správy na overleafe https://www.overleaf.com/project/5e7101e344e1ac0001e3041b\n",
    "- Experimenty\n",
    "    - DM metóda: experimentovanie, nastavenie parametrov, trénovanie, testovanie, ...\n",
    "    - vyhodnotenie: vyhodnotenie výsledkov, porovnanie metód (aj s publikovanými prácami)\n",
    "- Zhrnutie\n",
    "    - zhodnotenie toho, čo sa v rámci projektu podarilo\n",
    "    - náčrt ďalšieho vhodného smerovania projektu\n",
    "- Literatúra: zoznam použitej literatúry a ich citovanie v správe\n",
    "\n",
    "- pridat vizualizacie k Decision Tree\n",
    "\n",
    "- pridat nove modely\n",
    "    - RF\n",
    "    - SVR\n",
    "\n",
    "- hyperparameter tuning\n",
    "    - manual pri RF\n",
    "    - gridsearch / random search\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mirec\\Desktop\\08_fiit_ls_2019_2020\\OZNAL\\projekt\\oznal_project\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.special import inv_boxcox\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "from src import analysis, preprocessing2, feature_selection2, metrics2\n",
    "\n",
    "pd.set_option('max_rows', None)\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.00000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.51120</td>\n",
       "      <td>-122.25700</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.00000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25000</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.72100</td>\n",
       "      <td>-122.31900</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.73790</td>\n",
       "      <td>-122.23300</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.00000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.52080</td>\n",
       "      <td>-122.39300</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.00000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.61680</td>\n",
       "      <td>-122.04500</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date        price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000 221900.00000         3    1.00000         1180   \n",
       "1  6414100192  20141209T000000 538000.00000         3    2.25000         2570   \n",
       "2  5631500400  20150225T000000 180000.00000         2    1.00000          770   \n",
       "3  2487200875  20141209T000000 604000.00000         4    3.00000         1960   \n",
       "4  1954400510  20150218T000000 510000.00000         3    2.00000         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  condition  grade  sqft_above  \\\n",
       "0      5650 1.00000           0     0          3      7        1180   \n",
       "1      7242 2.00000           0     0          3      7        2170   \n",
       "2     10000 1.00000           0     0          3      6         770   \n",
       "3      5000 1.00000           0     0          5      7        1050   \n",
       "4      8080 1.00000           0     0          3      8        1680   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat       long  \\\n",
       "0              0      1955             0    98178 47.51120 -122.25700   \n",
       "1            400      1951          1991    98125 47.72100 -122.31900   \n",
       "2              0      1933             0    98028 47.73790 -122.23300   \n",
       "3            910      1965             0    98136 47.52080 -122.39300   \n",
       "4              0      1987             0    98074 47.61680 -122.04500   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_housing = \"data\\\\kc_house_data.csv\"\n",
    "df = pd.read_csv(path_housing, sep=\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test, price_lambda = preprocessing2.run_pipeline(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode_1</th>\n",
       "      <th>zipcode_2</th>\n",
       "      <th>zipcode_3</th>\n",
       "      <th>zipcode_4</th>\n",
       "      <th>zipcode_5</th>\n",
       "      <th>zipcode_6</th>\n",
       "      <th>zipcode_7</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>recon_age</th>\n",
       "      <th>price_per_sqft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12496</td>\n",
       "      <td>1982201345</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>7.38084</td>\n",
       "      <td>4.19603</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3.41952</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47.66390</td>\n",
       "      <td>-122.36400</td>\n",
       "      <td>7.04752</td>\n",
       "      <td>3.99849</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>4040800810</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25000</td>\n",
       "      <td>8.50943</td>\n",
       "      <td>4.29079</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3.46649</td>\n",
       "      <td>31.62278</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47.61880</td>\n",
       "      <td>-122.11400</td>\n",
       "      <td>7.63530</td>\n",
       "      <td>4.10521</td>\n",
       "      <td>51</td>\n",
       "      <td>0.00172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17400</td>\n",
       "      <td>7525410190</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75000</td>\n",
       "      <td>8.98009</td>\n",
       "      <td>4.52123</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3.66089</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47.57470</td>\n",
       "      <td>-122.03500</td>\n",
       "      <td>7.85941</td>\n",
       "      <td>4.09276</td>\n",
       "      <td>35</td>\n",
       "      <td>0.00131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17038</td>\n",
       "      <td>2326059099</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50000</td>\n",
       "      <td>9.14293</td>\n",
       "      <td>4.54771</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3.68127</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.72320</td>\n",
       "      <td>-122.13100</td>\n",
       "      <td>8.11672</td>\n",
       "      <td>4.09276</td>\n",
       "      <td>13</td>\n",
       "      <td>0.00157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5043</td>\n",
       "      <td>4219400290</td>\n",
       "      <td>5</td>\n",
       "      <td>2.75000</td>\n",
       "      <td>8.98009</td>\n",
       "      <td>4.32003</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3.66089</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1939</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47.65520</td>\n",
       "      <td>-122.27800</td>\n",
       "      <td>7.98616</td>\n",
       "      <td>4.06938</td>\n",
       "      <td>75</td>\n",
       "      <td>0.00169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
       "12496  1982201345         2    1.00000      7.38084   4.19603 1.00000   \n",
       "775    4040800810         3    2.25000      8.50943   4.29079 1.00000   \n",
       "17400  7525410190         3    1.75000      8.98009   4.52123 1.50000   \n",
       "17038  2326059099         4    2.50000      9.14293   4.54771 2.00000   \n",
       "5043   4219400290         5    2.75000      8.98009   4.32003 1.50000   \n",
       "\n",
       "       waterfront  view  condition  grade  sqft_above  sqft_basement  \\\n",
       "12496           0     0          4      7     3.41952        0.00000   \n",
       "775             0     0          4      8     3.46649       31.62278   \n",
       "17400           0     0          3      8     3.66089        0.00000   \n",
       "17038           0     0          3      9     3.68127        0.00000   \n",
       "5043            0     0          3      8     3.66089        0.00000   \n",
       "\n",
       "       yr_built  yr_renovated  zipcode_1  zipcode_2  zipcode_3  zipcode_4  \\\n",
       "12496      1944             0          0          0          0          0   \n",
       "775        1963             0          0          0          0          0   \n",
       "17400      1979             0          0          0          0          0   \n",
       "17038      2001             0          0          0          0          0   \n",
       "5043       1939             0          0          0          0          0   \n",
       "\n",
       "       zipcode_5  zipcode_6  zipcode_7      lat       long  sqft_living15  \\\n",
       "12496          0          0          1 47.66390 -122.36400        7.04752   \n",
       "775            0          1          0 47.61880 -122.11400        7.63530   \n",
       "17400          0          1          1 47.57470 -122.03500        7.85941   \n",
       "17038          1          0          0 47.72320 -122.13100        8.11672   \n",
       "5043           1          0          1 47.65520 -122.27800        7.98616   \n",
       "\n",
       "       sqft_lot15  recon_age  price_per_sqft  \n",
       "12496     3.99849         70         0.00248  \n",
       "775       4.10521         51         0.00172  \n",
       "17400     4.09276         35         0.00131  \n",
       "17038     4.09276         13         0.00157  \n",
       "5043      4.06938         75         0.00169  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenty\n",
    "\n",
    "Po predspracovaní dát nami vytvorenou pipeline, sme mali dáta rozdelené v pomere 70:20:10 (trénovacia : validačná : testovacia množina). Použili sme implementácie algoritmov z modulu sklearn. Najlepšie výsledky podľa metriky R$^2$ dosiahol model polynomiálnej regresie 3. stupňa s použitím selekcie čŕt RFE (0.916 na trénovacej a 0.828 na testovacej množine), druhý najlepší výsledok podľa tejto metriky dosiahol model regresného rozhodovacieho stromu(0.861 na trénovacej a 0.802 na testovacej množine). V prípade modelu jednoduchej lineárnej regresie sme vyskúšali aj 5, resp. 10 - násobnú krížovú validáciu, na porovnanie výsledkov s modelom jednoduchej lineárnej regresie trénovaného tradičným spôsobom, avšak tento prístup nám nepreukázal žiaden signifikantný rozdiel vo výsledkoch pri modeloch jednoduchej lineárnej regresie.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch pre LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum number of features: 22 (all features: 27)\n",
      "Score with 22 features: 0.754436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>Adj_R2_train</th>\n",
       "      <th>Adj_R2_test</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>36349984307.61000</td>\n",
       "      <td>190656.72000</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.75500</td>\n",
       "      <td>0.73000</td>\n",
       "      <td>0.75500</td>\n",
       "      <td>0.72900</td>\n",
       "      <td>{'C': 1.7214568800839372, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>36615664655.22000</td>\n",
       "      <td>191352.20000</td>\n",
       "      <td>0.27000</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.72900</td>\n",
       "      <td>0.74900</td>\n",
       "      <td>0.72700</td>\n",
       "      <td>{'C': 1.307898170860503, 'loss': 'epsilon_inse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>36386172326.41000</td>\n",
       "      <td>190751.60000</td>\n",
       "      <td>0.27000</td>\n",
       "      <td>0.76400</td>\n",
       "      <td>0.72700</td>\n",
       "      <td>0.76300</td>\n",
       "      <td>0.72600</td>\n",
       "      <td>{'C': 1.5344073305568182, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>36377943322.08000</td>\n",
       "      <td>190730.03000</td>\n",
       "      <td>0.27000</td>\n",
       "      <td>0.76400</td>\n",
       "      <td>0.72700</td>\n",
       "      <td>0.76300</td>\n",
       "      <td>0.72600</td>\n",
       "      <td>{'C': 1.7666620025132562, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>36440878118.94000</td>\n",
       "      <td>190894.94000</td>\n",
       "      <td>0.27000</td>\n",
       "      <td>0.76400</td>\n",
       "      <td>0.72600</td>\n",
       "      <td>0.76400</td>\n",
       "      <td>0.72500</td>\n",
       "      <td>{'C': 1.283269386130394, 'loss': 'epsilon_inse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>37076331434.13000</td>\n",
       "      <td>192552.15000</td>\n",
       "      <td>0.27000</td>\n",
       "      <td>0.74300</td>\n",
       "      <td>0.72600</td>\n",
       "      <td>0.74300</td>\n",
       "      <td>0.72500</td>\n",
       "      <td>{'C': 1.9910598311991934, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>36493687564.76000</td>\n",
       "      <td>191033.21000</td>\n",
       "      <td>0.27000</td>\n",
       "      <td>0.76400</td>\n",
       "      <td>0.72500</td>\n",
       "      <td>0.76400</td>\n",
       "      <td>0.72400</td>\n",
       "      <td>{'C': 1.4849318644445397, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>36542601339.55000</td>\n",
       "      <td>191161.19000</td>\n",
       "      <td>0.27000</td>\n",
       "      <td>0.76400</td>\n",
       "      <td>0.72500</td>\n",
       "      <td>0.76400</td>\n",
       "      <td>0.72300</td>\n",
       "      <td>{'C': 1.8890485876104075, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "      <td>37593592052.17000</td>\n",
       "      <td>193890.67000</td>\n",
       "      <td>0.27000</td>\n",
       "      <td>0.73600</td>\n",
       "      <td>0.72300</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>0.72100</td>\n",
       "      <td>{'C': 1.9714586808164296, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>36781777911.06000</td>\n",
       "      <td>191785.76000</td>\n",
       "      <td>0.27000</td>\n",
       "      <td>0.76500</td>\n",
       "      <td>0.72200</td>\n",
       "      <td>0.76400</td>\n",
       "      <td>0.72000</td>\n",
       "      <td>{'C': 1.339804277498328, 'loss': 'squared_epsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>38059826381.94000</td>\n",
       "      <td>195089.28000</td>\n",
       "      <td>0.27000</td>\n",
       "      <td>0.73000</td>\n",
       "      <td>0.72000</td>\n",
       "      <td>0.73000</td>\n",
       "      <td>0.71900</td>\n",
       "      <td>{'C': 1.8651812598736857, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>38780335616.58000</td>\n",
       "      <td>196927.23000</td>\n",
       "      <td>0.27000</td>\n",
       "      <td>0.72300</td>\n",
       "      <td>0.71600</td>\n",
       "      <td>0.72200</td>\n",
       "      <td>0.71400</td>\n",
       "      <td>{'C': 1.7214568800839372, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>37240995368.62000</td>\n",
       "      <td>192979.26000</td>\n",
       "      <td>0.27000</td>\n",
       "      <td>0.76300</td>\n",
       "      <td>0.71600</td>\n",
       "      <td>0.76300</td>\n",
       "      <td>0.71500</td>\n",
       "      <td>{'C': 1.8857806183159302, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>43</td>\n",
       "      <td>38936554104.74000</td>\n",
       "      <td>197323.48000</td>\n",
       "      <td>0.27000</td>\n",
       "      <td>0.72100</td>\n",
       "      <td>0.71500</td>\n",
       "      <td>0.72100</td>\n",
       "      <td>0.71400</td>\n",
       "      <td>{'C': 1.2674236547353868, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>37532266980.43000</td>\n",
       "      <td>193732.46000</td>\n",
       "      <td>0.28000</td>\n",
       "      <td>0.76200</td>\n",
       "      <td>0.71300</td>\n",
       "      <td>0.76200</td>\n",
       "      <td>0.71200</td>\n",
       "      <td>{'C': 1.5952413904679548, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>37892249013.54000</td>\n",
       "      <td>194659.32000</td>\n",
       "      <td>0.28000</td>\n",
       "      <td>0.76100</td>\n",
       "      <td>0.70900</td>\n",
       "      <td>0.76000</td>\n",
       "      <td>0.70700</td>\n",
       "      <td>{'C': 1.6933505690541306, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>41493789222.08000</td>\n",
       "      <td>203700.24000</td>\n",
       "      <td>0.28000</td>\n",
       "      <td>0.69500</td>\n",
       "      <td>0.69900</td>\n",
       "      <td>0.69500</td>\n",
       "      <td>0.69700</td>\n",
       "      <td>{'C': 1.2674236547353868, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>47</td>\n",
       "      <td>42579540578.24000</td>\n",
       "      <td>206348.11000</td>\n",
       "      <td>0.28000</td>\n",
       "      <td>0.68500</td>\n",
       "      <td>0.69200</td>\n",
       "      <td>0.68500</td>\n",
       "      <td>0.69100</td>\n",
       "      <td>{'C': 1.8857806183159302, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>42803672180.73000</td>\n",
       "      <td>206890.48000</td>\n",
       "      <td>0.28000</td>\n",
       "      <td>0.68300</td>\n",
       "      <td>0.69000</td>\n",
       "      <td>0.68200</td>\n",
       "      <td>0.68900</td>\n",
       "      <td>{'C': 1.6662069187380966, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>39736207411.62000</td>\n",
       "      <td>199339.43000</td>\n",
       "      <td>0.29000</td>\n",
       "      <td>0.74900</td>\n",
       "      <td>0.68700</td>\n",
       "      <td>0.74900</td>\n",
       "      <td>0.68600</td>\n",
       "      <td>{'C': 1.599661326752905, 'loss': 'squared_epsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>39931532684.23000</td>\n",
       "      <td>199828.76000</td>\n",
       "      <td>0.29000</td>\n",
       "      <td>0.74800</td>\n",
       "      <td>0.68500</td>\n",
       "      <td>0.74700</td>\n",
       "      <td>0.68400</td>\n",
       "      <td>{'C': 1.9470563389328914, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>48494956202.81000</td>\n",
       "      <td>220215.70000</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>0.63700</td>\n",
       "      <td>0.65800</td>\n",
       "      <td>0.63700</td>\n",
       "      <td>0.65600</td>\n",
       "      <td>{'C': 1.5441715118947954, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>42351734667.56000</td>\n",
       "      <td>205795.37000</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>0.72800</td>\n",
       "      <td>0.65600</td>\n",
       "      <td>0.72800</td>\n",
       "      <td>0.65400</td>\n",
       "      <td>{'C': 1.4873675513299995, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>42440985277.96000</td>\n",
       "      <td>206012.10000</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>0.72800</td>\n",
       "      <td>0.65500</td>\n",
       "      <td>0.72700</td>\n",
       "      <td>0.65300</td>\n",
       "      <td>{'C': 1.9470563389328914, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>49829395954.37000</td>\n",
       "      <td>223224.99000</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>0.62600</td>\n",
       "      <td>0.64900</td>\n",
       "      <td>0.62600</td>\n",
       "      <td>0.64800</td>\n",
       "      <td>{'C': 1.301331952197602, 'loss': 'epsilon_inse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>51812806941.06000</td>\n",
       "      <td>227624.27000</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>0.61200</td>\n",
       "      <td>0.63900</td>\n",
       "      <td>0.61100</td>\n",
       "      <td>0.63700</td>\n",
       "      <td>{'C': 1.4070477145322038, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>44</td>\n",
       "      <td>44090263096.59000</td>\n",
       "      <td>209976.82000</td>\n",
       "      <td>0.31000</td>\n",
       "      <td>0.71300</td>\n",
       "      <td>0.63400</td>\n",
       "      <td>0.71200</td>\n",
       "      <td>0.63200</td>\n",
       "      <td>{'C': 1.7666620025132562, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>40</td>\n",
       "      <td>44722293294.98000</td>\n",
       "      <td>211476.46000</td>\n",
       "      <td>0.31000</td>\n",
       "      <td>0.70700</td>\n",
       "      <td>0.62600</td>\n",
       "      <td>0.70600</td>\n",
       "      <td>0.62500</td>\n",
       "      <td>{'C': 1.4631937471686012, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>56317999408.63000</td>\n",
       "      <td>237314.14000</td>\n",
       "      <td>0.31000</td>\n",
       "      <td>0.58000</td>\n",
       "      <td>0.61400</td>\n",
       "      <td>0.57900</td>\n",
       "      <td>0.61200</td>\n",
       "      <td>{'C': 1.2674236547353868, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>35</td>\n",
       "      <td>56508318731.37000</td>\n",
       "      <td>237714.78000</td>\n",
       "      <td>0.32000</td>\n",
       "      <td>0.57800</td>\n",
       "      <td>0.61300</td>\n",
       "      <td>0.57800</td>\n",
       "      <td>0.61100</td>\n",
       "      <td>{'C': 1.9470563389328914, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>59955349335.55000</td>\n",
       "      <td>244857.81000</td>\n",
       "      <td>0.32000</td>\n",
       "      <td>0.55600</td>\n",
       "      <td>0.59500</td>\n",
       "      <td>0.55500</td>\n",
       "      <td>0.59300</td>\n",
       "      <td>{'C': 1.9653099946642358, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>39</td>\n",
       "      <td>47240695685.06000</td>\n",
       "      <td>217349.25000</td>\n",
       "      <td>0.33000</td>\n",
       "      <td>0.68100</td>\n",
       "      <td>0.59300</td>\n",
       "      <td>0.68100</td>\n",
       "      <td>0.59100</td>\n",
       "      <td>{'C': 1.5198786975891476, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>60797704219.59000</td>\n",
       "      <td>246571.90000</td>\n",
       "      <td>0.32000</td>\n",
       "      <td>0.55000</td>\n",
       "      <td>0.59000</td>\n",
       "      <td>0.55000</td>\n",
       "      <td>0.58800</td>\n",
       "      <td>{'C': 1.4104499618739195, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "      <td>63719106107.55000</td>\n",
       "      <td>252426.44000</td>\n",
       "      <td>0.33000</td>\n",
       "      <td>0.53300</td>\n",
       "      <td>0.57600</td>\n",
       "      <td>0.53200</td>\n",
       "      <td>0.57400</td>\n",
       "      <td>{'C': 1.6184123091256244, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>50478702332.08000</td>\n",
       "      <td>224674.66000</td>\n",
       "      <td>0.34000</td>\n",
       "      <td>0.64500</td>\n",
       "      <td>0.54900</td>\n",
       "      <td>0.64500</td>\n",
       "      <td>0.54700</td>\n",
       "      <td>{'C': 1.4135201528104362, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>34</td>\n",
       "      <td>69538170885.46001</td>\n",
       "      <td>263700.91000</td>\n",
       "      <td>0.34000</td>\n",
       "      <td>0.49700</td>\n",
       "      <td>0.54800</td>\n",
       "      <td>0.49700</td>\n",
       "      <td>0.54500</td>\n",
       "      <td>{'C': 1.5198786975891476, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>72882912208.08000</td>\n",
       "      <td>269968.35000</td>\n",
       "      <td>0.35000</td>\n",
       "      <td>0.47700</td>\n",
       "      <td>0.53100</td>\n",
       "      <td>0.47600</td>\n",
       "      <td>0.52800</td>\n",
       "      <td>{'C': 1.909293475391934, 'loss': 'squared_epsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>52308769134.00000</td>\n",
       "      <td>228711.10000</td>\n",
       "      <td>0.35000</td>\n",
       "      <td>0.62400</td>\n",
       "      <td>0.52300</td>\n",
       "      <td>0.62300</td>\n",
       "      <td>0.52100</td>\n",
       "      <td>{'C': 1.6430659186352958, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>76001311317.60001</td>\n",
       "      <td>275683.35000</td>\n",
       "      <td>0.35000</td>\n",
       "      <td>0.45900</td>\n",
       "      <td>0.51600</td>\n",
       "      <td>0.45800</td>\n",
       "      <td>0.51400</td>\n",
       "      <td>{'C': 1.6601719993948159, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>48</td>\n",
       "      <td>53153106089.85000</td>\n",
       "      <td>230549.57000</td>\n",
       "      <td>0.36000</td>\n",
       "      <td>0.61300</td>\n",
       "      <td>0.51100</td>\n",
       "      <td>0.61300</td>\n",
       "      <td>0.50800</td>\n",
       "      <td>{'C': 1.9313419676946117, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>80717681100.09000</td>\n",
       "      <td>284108.57000</td>\n",
       "      <td>0.36000</td>\n",
       "      <td>0.43300</td>\n",
       "      <td>0.49500</td>\n",
       "      <td>0.43300</td>\n",
       "      <td>0.49200</td>\n",
       "      <td>{'C': 1.5683934178120527, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>60587279404.74000</td>\n",
       "      <td>246144.83000</td>\n",
       "      <td>0.39000</td>\n",
       "      <td>0.51500</td>\n",
       "      <td>0.39600</td>\n",
       "      <td>0.51400</td>\n",
       "      <td>0.39300</td>\n",
       "      <td>{'C': 1.9714586808164296, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>62293094417.74000</td>\n",
       "      <td>249585.85000</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.49100</td>\n",
       "      <td>0.36800</td>\n",
       "      <td>0.49000</td>\n",
       "      <td>0.36500</td>\n",
       "      <td>{'C': 1.9152411834369392, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>112444663410.36000</td>\n",
       "      <td>335327.70000</td>\n",
       "      <td>0.41000</td>\n",
       "      <td>0.27500</td>\n",
       "      <td>0.36100</td>\n",
       "      <td>0.27400</td>\n",
       "      <td>0.35800</td>\n",
       "      <td>{'C': 1.9653099946642358, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>37</td>\n",
       "      <td>63306488644.48000</td>\n",
       "      <td>251607.81000</td>\n",
       "      <td>0.41000</td>\n",
       "      <td>0.47600</td>\n",
       "      <td>0.35200</td>\n",
       "      <td>0.47500</td>\n",
       "      <td>0.34900</td>\n",
       "      <td>{'C': 1.6381641463830443, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>67439012518.49000</td>\n",
       "      <td>259690.22000</td>\n",
       "      <td>0.43000</td>\n",
       "      <td>0.41300</td>\n",
       "      <td>0.28100</td>\n",
       "      <td>0.41200</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>{'C': 1.339804277498328, 'loss': 'epsilon_inse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>136767299212.99001</td>\n",
       "      <td>369820.63000</td>\n",
       "      <td>0.44000</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.27000</td>\n",
       "      <td>0.16900</td>\n",
       "      <td>0.26600</td>\n",
       "      <td>{'C': 1.9057184546412032, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>16</td>\n",
       "      <td>69860283119.46001</td>\n",
       "      <td>264310.96000</td>\n",
       "      <td>0.44000</td>\n",
       "      <td>0.37400</td>\n",
       "      <td>0.23800</td>\n",
       "      <td>0.37300</td>\n",
       "      <td>0.23400</td>\n",
       "      <td>{'C': 1.430739540528867, 'loss': 'squared_epsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>33</td>\n",
       "      <td>164876461529.13000</td>\n",
       "      <td>406049.83000</td>\n",
       "      <td>0.47000</td>\n",
       "      <td>0.05800</td>\n",
       "      <td>0.17200</td>\n",
       "      <td>0.05700</td>\n",
       "      <td>0.16800</td>\n",
       "      <td>{'C': 1.6430659186352958, 'loss': 'squared_eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>20</td>\n",
       "      <td>82888445619.59000</td>\n",
       "      <td>287903.54000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.14000</td>\n",
       "      <td>-0.01900</td>\n",
       "      <td>0.13800</td>\n",
       "      <td>-0.02400</td>\n",
       "      <td>{'C': 1.8890485876104075, 'loss': 'epsilon_ins...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                MSE         RMSE   RMSLE R2_train  R2_test  \\\n",
       "0      17  36349984307.61000 190656.72000 0.26000  0.75500  0.73000   \n",
       "1      24  36615664655.22000 191352.20000 0.27000  0.75000  0.72900   \n",
       "2      28  36386172326.41000 190751.60000 0.27000  0.76400  0.72700   \n",
       "3       1  36377943322.08000 190730.03000 0.27000  0.76400  0.72700   \n",
       "4      36  36440878118.94000 190894.94000 0.27000  0.76400  0.72600   \n",
       "5      29  37076331434.13000 192552.15000 0.27000  0.74300  0.72600   \n",
       "6      12  36493687564.76000 191033.21000 0.27000  0.76400  0.72500   \n",
       "7      41  36542601339.55000 191161.19000 0.27000  0.76400  0.72500   \n",
       "8      49  37593592052.17000 193890.67000 0.27000  0.73600  0.72300   \n",
       "9      21  36781777911.06000 191785.76000 0.27000  0.76500  0.72200   \n",
       "10     25  38059826381.94000 195089.28000 0.27000  0.73000  0.72000   \n",
       "11      2  38780335616.58000 196927.23000 0.27000  0.72300  0.71600   \n",
       "12      4  37240995368.62000 192979.26000 0.27000  0.76300  0.71600   \n",
       "13     43  38936554104.74000 197323.48000 0.27000  0.72100  0.71500   \n",
       "14      3  37532266980.43000 193732.46000 0.28000  0.76200  0.71300   \n",
       "15     26  37892249013.54000 194659.32000 0.28000  0.76100  0.70900   \n",
       "16     22  41493789222.08000 203700.24000 0.28000  0.69500  0.69900   \n",
       "17     47  42579540578.24000 206348.11000 0.28000  0.68500  0.69200   \n",
       "18     32  42803672180.73000 206890.48000 0.28000  0.68300  0.69000   \n",
       "19     27  39736207411.62000 199339.43000 0.29000  0.74900  0.68700   \n",
       "20     13  39931532684.23000 199828.76000 0.29000  0.74800  0.68500   \n",
       "21      5  48494956202.81000 220215.70000 0.30000  0.63700  0.65800   \n",
       "22      9  42351734667.56000 205795.37000 0.30000  0.72800  0.65600   \n",
       "23     14  42440985277.96000 206012.10000 0.30000  0.72800  0.65500   \n",
       "24     31  49829395954.37000 223224.99000 0.30000  0.62600  0.64900   \n",
       "25     11  51812806941.06000 227624.27000 0.30000  0.61200  0.63900   \n",
       "26     44  44090263096.59000 209976.82000 0.31000  0.71300  0.63400   \n",
       "27     40  44722293294.98000 211476.46000 0.31000  0.70700  0.62600   \n",
       "28     18  56317999408.63000 237314.14000 0.31000  0.58000  0.61400   \n",
       "29     35  56508318731.37000 237714.78000 0.32000  0.57800  0.61300   \n",
       "30     19  59955349335.55000 244857.81000 0.32000  0.55600  0.59500   \n",
       "31     39  47240695685.06000 217349.25000 0.33000  0.68100  0.59300   \n",
       "32     15  60797704219.59000 246571.90000 0.32000  0.55000  0.59000   \n",
       "33     23  63719106107.55000 252426.44000 0.33000  0.53300  0.57600   \n",
       "34      7  50478702332.08000 224674.66000 0.34000  0.64500  0.54900   \n",
       "35     34  69538170885.46001 263700.91000 0.34000  0.49700  0.54800   \n",
       "36      6  72882912208.08000 269968.35000 0.35000  0.47700  0.53100   \n",
       "37      0  52308769134.00000 228711.10000 0.35000  0.62400  0.52300   \n",
       "38     38  76001311317.60001 275683.35000 0.35000  0.45900  0.51600   \n",
       "39     48  53153106089.85000 230549.57000 0.36000  0.61300  0.51100   \n",
       "40     10  80717681100.09000 284108.57000 0.36000  0.43300  0.49500   \n",
       "41     30  60587279404.74000 246144.83000 0.39000  0.51500  0.39600   \n",
       "42     42  62293094417.74000 249585.85000 0.40000  0.49100  0.36800   \n",
       "43     46 112444663410.36000 335327.70000 0.41000  0.27500  0.36100   \n",
       "44     37  63306488644.48000 251607.81000 0.41000  0.47600  0.35200   \n",
       "45     45  67439012518.49000 259690.22000 0.43000  0.41300  0.28100   \n",
       "46      8 136767299212.99001 369820.63000 0.44000  0.17000  0.27000   \n",
       "47     16  69860283119.46001 264310.96000 0.44000  0.37400  0.23800   \n",
       "48     33 164876461529.13000 406049.83000 0.47000  0.05800  0.17200   \n",
       "49     20  82888445619.59000 287903.54000 0.50000  0.14000 -0.01900   \n",
       "\n",
       "   Adj_R2_train Adj_R2_test                                             params  \n",
       "0       0.75500     0.72900  {'C': 1.7214568800839372, 'loss': 'epsilon_ins...  \n",
       "1       0.74900     0.72700  {'C': 1.307898170860503, 'loss': 'epsilon_inse...  \n",
       "2       0.76300     0.72600  {'C': 1.5344073305568182, 'loss': 'epsilon_ins...  \n",
       "3       0.76300     0.72600  {'C': 1.7666620025132562, 'loss': 'squared_eps...  \n",
       "4       0.76400     0.72500  {'C': 1.283269386130394, 'loss': 'epsilon_inse...  \n",
       "5       0.74300     0.72500  {'C': 1.9910598311991934, 'loss': 'epsilon_ins...  \n",
       "6       0.76400     0.72400  {'C': 1.4849318644445397, 'loss': 'epsilon_ins...  \n",
       "7       0.76400     0.72300  {'C': 1.8890485876104075, 'loss': 'squared_eps...  \n",
       "8       0.73500     0.72100  {'C': 1.9714586808164296, 'loss': 'squared_eps...  \n",
       "9       0.76400     0.72000  {'C': 1.339804277498328, 'loss': 'squared_epsi...  \n",
       "10      0.73000     0.71900  {'C': 1.8651812598736857, 'loss': 'epsilon_ins...  \n",
       "11      0.72200     0.71400  {'C': 1.7214568800839372, 'loss': 'squared_eps...  \n",
       "12      0.76300     0.71500  {'C': 1.8857806183159302, 'loss': 'squared_eps...  \n",
       "13      0.72100     0.71400  {'C': 1.2674236547353868, 'loss': 'epsilon_ins...  \n",
       "14      0.76200     0.71200  {'C': 1.5952413904679548, 'loss': 'epsilon_ins...  \n",
       "15      0.76000     0.70700  {'C': 1.6933505690541306, 'loss': 'squared_eps...  \n",
       "16      0.69500     0.69700  {'C': 1.2674236547353868, 'loss': 'squared_eps...  \n",
       "17      0.68500     0.69100  {'C': 1.8857806183159302, 'loss': 'epsilon_ins...  \n",
       "18      0.68200     0.68900  {'C': 1.6662069187380966, 'loss': 'squared_eps...  \n",
       "19      0.74900     0.68600  {'C': 1.599661326752905, 'loss': 'squared_epsi...  \n",
       "20      0.74700     0.68400  {'C': 1.9470563389328914, 'loss': 'epsilon_ins...  \n",
       "21      0.63700     0.65600  {'C': 1.5441715118947954, 'loss': 'epsilon_ins...  \n",
       "22      0.72800     0.65400  {'C': 1.4873675513299995, 'loss': 'epsilon_ins...  \n",
       "23      0.72700     0.65300  {'C': 1.9470563389328914, 'loss': 'squared_eps...  \n",
       "24      0.62600     0.64800  {'C': 1.301331952197602, 'loss': 'epsilon_inse...  \n",
       "25      0.61100     0.63700  {'C': 1.4070477145322038, 'loss': 'epsilon_ins...  \n",
       "26      0.71200     0.63200  {'C': 1.7666620025132562, 'loss': 'epsilon_ins...  \n",
       "27      0.70600     0.62500  {'C': 1.4631937471686012, 'loss': 'epsilon_ins...  \n",
       "28      0.57900     0.61200  {'C': 1.2674236547353868, 'loss': 'epsilon_ins...  \n",
       "29      0.57800     0.61100  {'C': 1.9470563389328914, 'loss': 'squared_eps...  \n",
       "30      0.55500     0.59300  {'C': 1.9653099946642358, 'loss': 'epsilon_ins...  \n",
       "31      0.68100     0.59100  {'C': 1.5198786975891476, 'loss': 'epsilon_ins...  \n",
       "32      0.55000     0.58800  {'C': 1.4104499618739195, 'loss': 'epsilon_ins...  \n",
       "33      0.53200     0.57400  {'C': 1.6184123091256244, 'loss': 'squared_eps...  \n",
       "34      0.64500     0.54700  {'C': 1.4135201528104362, 'loss': 'squared_eps...  \n",
       "35      0.49700     0.54500  {'C': 1.5198786975891476, 'loss': 'epsilon_ins...  \n",
       "36      0.47600     0.52800  {'C': 1.909293475391934, 'loss': 'squared_epsi...  \n",
       "37      0.62300     0.52100  {'C': 1.6430659186352958, 'loss': 'squared_eps...  \n",
       "38      0.45800     0.51400  {'C': 1.6601719993948159, 'loss': 'squared_eps...  \n",
       "39      0.61300     0.50800  {'C': 1.9313419676946117, 'loss': 'squared_eps...  \n",
       "40      0.43300     0.49200  {'C': 1.5683934178120527, 'loss': 'squared_eps...  \n",
       "41      0.51400     0.39300  {'C': 1.9714586808164296, 'loss': 'squared_eps...  \n",
       "42      0.49000     0.36500  {'C': 1.9152411834369392, 'loss': 'epsilon_ins...  \n",
       "43      0.27400     0.35800  {'C': 1.9653099946642358, 'loss': 'epsilon_ins...  \n",
       "44      0.47500     0.34900  {'C': 1.6381641463830443, 'loss': 'squared_eps...  \n",
       "45      0.41200     0.27700  {'C': 1.339804277498328, 'loss': 'epsilon_inse...  \n",
       "46      0.16900     0.26600  {'C': 1.9057184546412032, 'loss': 'squared_eps...  \n",
       "47      0.37300     0.23400  {'C': 1.430739540528867, 'loss': 'squared_epsi...  \n",
       "48      0.05700     0.16800  {'C': 1.6430659186352958, 'loss': 'squared_eps...  \n",
       "49      0.13800    -0.02400  {'C': 1.8890485876104075, 'loss': 'epsilon_ins...  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def objective(hyperparameters, iteration, features1):\n",
    "\n",
    "    clf = LinearSVR(**hyperparameters)\n",
    "    X_my_train = X_train[features1]#.values.reshape(-1,1)\n",
    "    X_my_valid = X_valid[features1]#.values.reshape(-1,1)\n",
    "\n",
    "    clf.fit(X_my_train, np.ravel(y_train))\n",
    "\n",
    "    y_hat = clf.predict(X_my_valid)\n",
    "    mean_squared_error=metrics.mean_squared_error(inv_boxcox(y_valid, price_lambda),inv_boxcox(y_hat, price_lambda))\n",
    "    rmlse = metrics.mean_squared_log_error(inv_boxcox(y_valid, price_lambda), inv_boxcox(y_hat, price_lambda))\n",
    "\n",
    "    r2_train = clf.score(X_my_train, y_train)\n",
    "    r2_test = clf.score(X_my_valid, y_valid)\n",
    "    adj_r2_train = 1 - (((1 - r2_train) * (X_my_train.shape[0] - 1)) / (X_my_train.shape[0] - X_my_train.shape[1] - 1))\n",
    "    adj_r2_test = 1 - (((1 - r2_test) * (X_my_valid.shape[0] - 1)) / (X_my_valid.shape[0] - X_my_valid.shape[1] - 1))\n",
    "    \n",
    "    score = {\n",
    "        \"MSE\": round(mean_squared_error, 2),\n",
    "        \"RMSE\": round(np.sqrt(mean_squared_error),2),\n",
    "        \"RMSLE\": round(np.sqrt(rmlse),2),\n",
    "        \"R2_train\": round(r2_train,3),\n",
    "        \"R2_test\": round(r2_test,3),\n",
    "        \"Adj_R2_train\": round(adj_r2_train,3),\n",
    "        \"Adj_R2_test\": round(adj_r2_test,3)\n",
    "    }\n",
    "    \n",
    "    return [score, hyperparameters]\n",
    "\n",
    "\n",
    "def random_search(param_grid, max_iterations, features):\n",
    "    \n",
    "    df_results = pd.DataFrame(columns = ['MSE', 'RMSE', 'RMSLE', 'R2_train', 'R2_test', 'Adj_R2_train', 'Adj_R2_test', 'params'],\n",
    "                                  index = list(range(max_iterations)))\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        hyperparameters = {k: random.choice(v) for k, v in param_grid.items()}\n",
    "        \n",
    "        eval_results = objective(hyperparameters, i, features)\n",
    "        for k,v in eval_results[0].items():\n",
    "            df_results[k][i] = v\n",
    "        df_results['params'][i] = eval_results[1]\n",
    "    \n",
    "    # Sort with best score on top\n",
    "    df_results.sort_values('R2_test', ascending = False, inplace = True)\n",
    "    df_results.reset_index(inplace=True)\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "param_grid = {\n",
    "     \"C\": np.random.uniform(1.2, 2.0, 100),\n",
    "#     \"dual\":[True],\n",
    "#     \"epsilon\":np.random.uniform(0.1, 0.2, 100),\n",
    "#     \"fit_intercept\":[True],\n",
    "#     \"intercept_scaling\":[1],\n",
    "    \"loss\":['epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    \"max_iter\":[20000],\n",
    "    \"tol\":np.random.uniform(1e-6, 5e-4, 100),\n",
    "#     \"verbose\":[0]\n",
    "}\n",
    "\n",
    "random.seed(50)\n",
    "features1 = feature_selection2.select_features_RFE(X_train, X_valid, y_train, y_valid)\n",
    "df_results = random_search(param_grid, 50, features1)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.7214568800839372,\n",
       " 'loss': 'epsilon_insensitive',\n",
       " 'max_iter': 20000,\n",
       " 'tol': 0.0004935410206914095}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_results.sort_values(['R2_test'], ascending = False, inplace = True)\n",
    "df_results['params'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jednoduchá lineárna regresia - sqft_living"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear model - sqft_living\n",
      "Mean Squared Error 60379753642.67178\n",
      "Root Mean Squared Error 245722.92047\n",
      "Root Mean Squared Log Error 0.39115\n",
      "R squared training 0.451\n",
      "R squared testing 0.402\n",
      "Adjusted-R squared training 0.451\n",
      "Adjusted-R squared testing 0.402\n",
      "intercept [3.78442207]\n",
      "coefficient [[0.02965959]]\n"
     ]
    }
   ],
   "source": [
    "reg=linear_model.LinearRegression()\n",
    "x_train=np.array(X_train['sqft_living']).reshape(-1,1)\n",
    "y_train=np.array(y_train).reshape(-1,1)\n",
    "reg.fit(x_train,y_train)\n",
    "\n",
    "x_test=np.array(X_valid['sqft_living']).reshape(-1,1)\n",
    "y_test=np.array(y_valid).reshape(-1,1)\n",
    "pred=reg.predict(x_test)\n",
    "print('linear model - sqft_living')\n",
    "\n",
    "metrics2.evaluate(reg, x_train, y_train, x_test, y_test, pred, price_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-násobná krížová validácia pri jednoduchej lineárnej regresii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: 0.4388515347655395\n",
      "Cross-validated scores: 0.4385100197794961\n"
     ]
    }
   ],
   "source": [
    "reg=linear_model.LinearRegression()\n",
    "k = 5\n",
    "\n",
    "X_try = pd.concat([X_train['sqft_living'], X_valid['sqft_living']])\n",
    "y_try = np.concatenate((np.array(y_train).reshape(-1,1), np.array(y_valid).reshape(-1,1)), axis=0)\n",
    "\n",
    "scores = cross_val_score(reg,  np.array(X_try).reshape(-1,1), np.array(y_try).reshape(-1,1), cv=k)\n",
    "print(\"Cross-validated scores:\", scores.mean())\n",
    "k = 10\n",
    "scores = cross_val_score(reg,  np.array(X_try).reshape(-1,1), np.array(y_try).reshape(-1,1), cv=k)\n",
    "print(\"Cross-validated scores:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jednoduchá lineárna regresia - grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear model - grade\n",
      "Mean Squared Error 55001939903.94096\n",
      "Root Mean Squared Error 234524.92384\n",
      "Root Mean Squared Log Error 0.38054\n",
      "R squared training 0.477\n",
      "R squared testing 0.432\n",
      "Adjusted-R squared training 0.477\n",
      "Adjusted-R squared testing 0.432\n",
      "intercept [3.93205218]\n",
      "coefficient [[0.01344416]]\n"
     ]
    }
   ],
   "source": [
    "reg=linear_model.LinearRegression()\n",
    "x_train=np.array(X_train['grade']).reshape(-1,1)\n",
    "y_train=np.array(y_train).reshape(-1,1)\n",
    "reg.fit(x_train,y_train)\n",
    "\n",
    "x_test=np.array(X_valid['grade']).reshape(-1,1)\n",
    "y_test=np.array(y_valid).reshape(-1,1)\n",
    "pred=reg.predict(x_test)\n",
    "print('linear model - grade')\n",
    "\n",
    "metrics2.evaluate(reg, x_train, y_train, x_test, y_test, pred, price_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viacnásobná lineárna regresia - part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple linear regression 1\n",
      "Mean Squared Error 47639437017.58308\n",
      "Root Mean Squared Error 218264.60322\n",
      "Root Mean Squared Log Error 0.35606\n",
      "R squared training 0.552\n",
      "R squared testing 0.501\n",
      "Adjusted-R squared training 0.551\n",
      "Adjusted-R squared testing 0.501\n",
      "intercept [3.96037582]\n",
      "coefficient [[-0.00035035  0.01953801  0.00850982 -0.06343591  0.00938436]]\n"
     ]
    }
   ],
   "source": [
    "features1 = feature_selection2.feature_filter(X_train, y_train, threshold=0.5)\n",
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(X_train[features1],y_train)\n",
    "\n",
    "pred=reg.predict(X_valid[features1])\n",
    "\n",
    "print('multiple linear regression 1')\n",
    "metrics2.evaluate(reg, X_train[features1], y_train, X_valid[features1], y_valid, pred, price_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viacnásobná lineárna regresia - part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple linear regression 2\n",
      "Mean Squared Error 34944367428.43664\n",
      "Root Mean Squared Error 186934.12591\n",
      "Root Mean Squared Log Error 0.25884\n",
      "R squared training 0.781\n",
      "R squared testing 0.744\n",
      "Adjusted-R squared training 0.781\n",
      "Adjusted-R squared testing 0.744\n",
      "intercept [1.48311087]\n",
      "coefficient [[ 1.51482623e-02  3.41215946e-03  3.78452993e-03  2.31928488e-03\n",
      "   7.04038947e-03 -1.43355076e-04 -2.82001549e-03  5.83690344e-02\n",
      "  -2.81136532e-02 -1.12521301e+01]]\n"
     ]
    }
   ],
   "source": [
    "features2 = feature_selection2.select_features_SFS(X_train, y_train, linear_model.LinearRegression)\n",
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(X_train[features2],y_train)\n",
    "\n",
    "pred=reg.predict(X_valid[features2])\n",
    "\n",
    "print('multiple linear regression 2')\n",
    "metrics2.evaluate(reg, X_train[features2], y_train, X_valid[features2], y_valid, pred, price_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-násobná krížová validácia pri viacnásobnej lineárnej regresii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: 0.7717217788661574\n",
      "Cross-validated scores: 0.7718156434452166\n"
     ]
    }
   ],
   "source": [
    "reg=linear_model.LinearRegression()\n",
    "k = 5\n",
    "\n",
    "X_try = pd.concat([X_train[features2], X_valid[features2]])\n",
    "y_try = np.concatenate((np.array(y_train).reshape(-1,1), np.array(y_valid).reshape(-1,1)), axis=0)\n",
    "\n",
    "scores = cross_val_score(reg,  X_try[features2], np.array(y_try).reshape(-1,1), cv=k)\n",
    "print(\"Cross-validated scores:\", scores.mean())\n",
    "k = 10\n",
    "scores = cross_val_score(reg,  X_try[features2], np.array(y_try).reshape(-1,1), cv=k)\n",
    "print(\"Cross-validated scores:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viacnásobná lineárna regresia - part3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum number of features: 22 (all features: 27)\n",
      "Score with 22 features: 0.754436\n",
      "multiple linear regression 3\n",
      "Mean Squared Error 32486651893.39338\n",
      "Root Mean Squared Error 180240.53898\n",
      "Root Mean Squared Log Error 0.25336\n",
      "R squared training 0.793\n",
      "R squared testing 0.754\n",
      "Adjusted-R squared training 0.793\n",
      "Adjusted-R squared testing 0.753\n",
      "intercept [0.41032586]\n",
      "coefficient [[-1.25747645e-03  1.91255673e-03  1.36418094e-02 -9.06972876e-03\n",
      "   2.82037240e-03  9.64036987e-03  2.72934373e-03  2.28954703e-03\n",
      "   6.11502524e-03 -1.41317852e-04  2.31738952e-03 -2.60579557e-03\n",
      "   9.45836431e-04 -1.05520017e-03 -9.45611848e-04  1.39617770e-03\n",
      "   4.85389928e-04  6.01748108e-02 -7.75492425e-03  7.45740712e-03\n",
      "  -1.89647156e-02 -1.07826081e+01]]\n"
     ]
    }
   ],
   "source": [
    "features3 = feature_selection2.select_features_RFE(X_train, X_valid, y_train, y_valid)\n",
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(X_train[features3],y_train)\n",
    "\n",
    "pred=reg.predict(X_valid[features3])\n",
    "\n",
    "print('multiple linear regression 3')\n",
    "metrics2.evaluate(reg, X_train[features3], y_train, X_valid[features3], y_valid, pred, price_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomiálna regresia 2. stupňa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial regresion - grade 2\n",
      "Mean Squared Error 25599854129.10427\n",
      "Root Mean Squared Error 159999.54415\n",
      "Root Mean Squared Log Error 0.23187\n",
      "R squared training 0.828\n",
      "R squared testing 0.789\n",
      "Adjusted-R squared training 0.828\n",
      "Adjusted-R squared testing 0.789\n"
     ]
    }
   ],
   "source": [
    "features1 = feature_selection2.select_features_SFS(X_train, y_train, linear_model.LinearRegression)\n",
    "\n",
    "polyfeat=PolynomialFeatures(degree=2)\n",
    "xtrain_poly=polyfeat.fit_transform(X_train[features1])\n",
    "xvalid_poly=polyfeat.fit_transform(X_valid[features1])\n",
    "\n",
    "np_y_train = np.array(y_train).reshape(-1,1)\n",
    "np_y_valid = np.array(y_valid).reshape(-1,1)\n",
    "\n",
    "poly=linear_model.LinearRegression()\n",
    "poly.fit(xtrain_poly,np_y_train)\n",
    "polypred=poly.predict(xvalid_poly)\n",
    "\n",
    "print('Polynomial regresion - grade 2')\n",
    "\n",
    "mean_squared_error=metrics.mean_squared_error(inv_boxcox(np_y_valid, price_lambda),inv_boxcox(polypred, price_lambda))\n",
    "rmlse = metrics.mean_squared_log_error(inv_boxcox(np_y_valid, price_lambda),inv_boxcox(polypred, price_lambda))\n",
    "\n",
    "r2_train = poly.score(xtrain_poly, np_y_train)\n",
    "r2_test = poly.score(xvalid_poly, np_y_valid)\n",
    "adj_r2_train = 1 - (((1 - r2_train) * (X_train[features1].shape[0] - 1)) / (X_train[features1].shape[0] - X_train[features1].shape[1] - 1))\n",
    "adj_r2_test = 1 - (((1 - r2_test) * (X_valid[features1].shape[0] - 1)) / (X_valid[features1].shape[0] - X_valid[features1].shape[1] - 1))\n",
    "\n",
    "print('Mean Squared Error', round(mean_squared_error, 5))\n",
    "print('Root Mean Squared Error', round(np.sqrt(mean_squared_error),5))\n",
    "print('Root Mean Squared Log Error', round(np.sqrt(rmlse),5))\n",
    "print('R squared training',round(r2_train,3))\n",
    "print('R squared testing',round(r2_test,3))\n",
    "print('Adjusted-R squared training', round(adj_r2_train,3))\n",
    "print('Adjusted-R squared testing', round(adj_r2_test,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomiálna regresia 3. stupňa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum number of features: 22 (all features: 27)\n",
      "Score with 22 features: 0.754436\n",
      "Polynomial regresion - grade 3\n",
      "Mean Squared Error 236372347755.9625\n",
      "Root Mean Squared Error 486181.39388\n",
      "Root Mean Squared Log Error 0.21942\n",
      "R squared training 0.916\n",
      "R squared testing 0.828\n",
      "Adjusted-R squared training 0.916\n",
      "Adjusted-R squared testing 0.827\n"
     ]
    }
   ],
   "source": [
    "features1 = feature_selection2.select_features_RFE(X_train, X_valid, y_train, y_valid)\n",
    "\n",
    "polyfeat=PolynomialFeatures(degree=3)\n",
    "xtrain_poly=polyfeat.fit_transform(X_train[features1])\n",
    "xvalid_poly=polyfeat.fit_transform(X_valid[features1])\n",
    "np_y_train = np.array(y_train).reshape(-1,1)\n",
    "np_y_valid = np.array(y_valid).reshape(-1,1)\n",
    "\n",
    "poly=linear_model.LinearRegression()\n",
    "poly.fit(xtrain_poly,np_y_train)\n",
    "polypred=poly.predict(xvalid_poly)\n",
    "\n",
    "print('Polynomial regresion - grade 3')\n",
    "mean_squared_error=metrics.mean_squared_error(inv_boxcox(np_y_valid, price_lambda),inv_boxcox(polypred, price_lambda))\n",
    "rmlse = metrics.mean_squared_log_error(inv_boxcox(np_y_valid, price_lambda),inv_boxcox(polypred, price_lambda))\n",
    "\n",
    "r2_train = poly.score(xtrain_poly, np_y_train)\n",
    "r2_test = poly.score(xvalid_poly, np_y_valid)\n",
    "adj_r2_train = 1 - (((1 - r2_train) * (X_train[features1].shape[0] - 1)) / (X_train[features1].shape[0] - X_train[features1].shape[1] - 1))\n",
    "adj_r2_test = 1 - (((1 - r2_test) * (X_valid[features1].shape[0] - 1)) / (X_valid[features1].shape[0] - X_valid[features1].shape[1] - 1))\n",
    "\n",
    "print('Mean Squared Error', round(mean_squared_error, 5))\n",
    "print('Root Mean Squared Error', round(np.sqrt(mean_squared_error),5))\n",
    "print('Root Mean Squared Log Error', round(np.sqrt(rmlse),5))\n",
    "print('R squared training',round(r2_train,3))\n",
    "print('R squared testing',round(r2_test,3))\n",
    "print('Adjusted-R squared training', round(adj_r2_train,3))\n",
    "print('Adjusted-R squared testing', round(adj_r2_test,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bedrooms',\n",
       " 'bathrooms',\n",
       " 'sqft_living',\n",
       " 'sqft_lot',\n",
       " 'floors',\n",
       " 'waterfront',\n",
       " 'view',\n",
       " 'condition',\n",
       " 'grade',\n",
       " 'yr_built',\n",
       " 'zipcode_1',\n",
       " 'zipcode_2',\n",
       " 'zipcode_3',\n",
       " 'zipcode_4',\n",
       " 'zipcode_5',\n",
       " 'zipcode_6',\n",
       " 'zipcode_7',\n",
       " 'lat',\n",
       " 'long',\n",
       " 'sqft_living15',\n",
       " 'sqft_lot15',\n",
       " 'price_per_sqft']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresný rozhodovací strom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error 23452266212.47\n",
      "Root Mean Squared Error 153141.33\n",
      "Root Mean Squared Log Error 0.23\n",
      "R squared training 0.861\n",
      "R squared testing 0.802\n",
      "Adjusted-R squared training 0.861\n",
      "Adjusted-R squared testing 0.801\n"
     ]
    }
   ],
   "source": [
    "regr_1 = DecisionTreeRegressor(max_depth=8)\n",
    "regr_1.fit(X_train, y_train)\n",
    "\n",
    "y_1 = regr_1.predict(X_valid)\n",
    "mean_squared_error=metrics.mean_squared_error(inv_boxcox(y_valid, price_lambda),inv_boxcox(y_1, price_lambda))\n",
    "rmlse = metrics.mean_squared_log_error(inv_boxcox(y_valid, price_lambda), inv_boxcox(y_1, price_lambda))\n",
    "\n",
    "r2_train = regr_1.score(X_train, y_train)\n",
    "r2_test = regr_1.score(X_valid, y_valid)\n",
    "adj_r2_train = 1 - (((1 - r2_train) * (X_train.shape[0] - 1)) / (X_train.shape[0] - X_train.shape[1] - 1))\n",
    "adj_r2_test = 1 - (((1 - r2_test) * (X_valid.shape[0] - 1)) / (X_valid.shape[0] - X_valid.shape[1] - 1))\n",
    "\n",
    "print('Mean Squared Error', round(mean_squared_error, 2))\n",
    "print('Root Mean Squared Error', round(np.sqrt(mean_squared_error),2))\n",
    "print('Root Mean Squared Log Error', round(np.sqrt(rmlse),2))\n",
    "print('R squared training',round(r2_train,3))\n",
    "print('R squared testing',round(r2_test,3))\n",
    "print('Adjusted-R squared training', round(adj_r2_train,3))\n",
    "print('Adjusted-R squared testing', round(adj_r2_test,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresný rozhodovací strom - časť 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error 23462962763.31\n",
      "Root Mean Squared Error 153176.25\n",
      "Root Mean Squared Log Error 0.23\n",
      "R squared training 0.861\n",
      "R squared testing 0.802\n",
      "Adjusted-R squared training 0.861\n",
      "Adjusted-R squared testing 0.801\n"
     ]
    }
   ],
   "source": [
    "regr_1 = DecisionTreeRegressor(max_depth=8)\n",
    "regr_1.fit(X_train, y_train)\n",
    "\n",
    "y_1 = regr_1.predict(X_valid)\n",
    "mean_squared_error=metrics.mean_squared_error(inv_boxcox(y_valid, price_lambda),inv_boxcox(y_1, price_lambda))\n",
    "rmlse = metrics.mean_squared_log_error(inv_boxcox(y_valid, price_lambda), inv_boxcox(y_1, price_lambda))\n",
    "\n",
    "r2_train = regr_1.score(X_train, y_train)\n",
    "r2_test = regr_1.score(X_valid, y_valid)\n",
    "adj_r2_train = 1 - (((1 - r2_train) * (X_train.shape[0] - 1)) / (X_train.shape[0] - X_train.shape[1] - 1))\n",
    "adj_r2_test = 1 - (((1 - r2_test) * (X_valid.shape[0] - 1)) / (X_valid.shape[0] - X_valid.shape[1] - 1))\n",
    "\n",
    "print('Mean Squared Error', round(mean_squared_error, 2))\n",
    "print('Root Mean Squared Error', round(np.sqrt(mean_squared_error),2))\n",
    "print('Root Mean Squared Log Error', round(np.sqrt(rmlse),2))\n",
    "print('R squared training',round(r2_train,3))\n",
    "print('R squared testing',round(r2_test,3))\n",
    "print('Adjusted-R squared training', round(adj_r2_train,3))\n",
    "print('Adjusted-R squared testing', round(adj_r2_test,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Náhodný les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error 19663274270.47\n",
      "Root Mean Squared Error 140225.8\n",
      "Root Mean Squared Log Error 0.2\n",
      "R squared training 0.893\n",
      "R squared testing 0.843\n",
      "Adjusted-R squared training 0.893\n",
      "Adjusted-R squared testing 0.842\n"
     ]
    }
   ],
   "source": [
    "reg_rf = RandomForestRegressor(n_estimators=100, max_depth=8)\n",
    "reg_rf.fit(X_train, y_train)\n",
    "\n",
    "y_hat = reg_rf.predict(X_valid)\n",
    "mean_squared_error=metrics.mean_squared_error(inv_boxcox(y_valid, price_lambda),inv_boxcox(y_hat, price_lambda))\n",
    "rmlse = metrics.mean_squared_log_error(inv_boxcox(y_valid, price_lambda), inv_boxcox(y_hat, price_lambda))\n",
    "\n",
    "r2_train = reg_rf.score(X_train, y_train)\n",
    "r2_test = reg_rf.score(X_valid, y_valid)\n",
    "adj_r2_train = 1 - (((1 - r2_train) * (X_train.shape[0] - 1)) / (X_train.shape[0] - X_train.shape[1] - 1))\n",
    "adj_r2_test = 1 - (((1 - r2_test) * (X_valid.shape[0] - 1)) / (X_valid.shape[0] - X_valid.shape[1] - 1))\n",
    "\n",
    "print('Mean Squared Error', round(mean_squared_error, 2))\n",
    "print('Root Mean Squared Error', round(np.sqrt(mean_squared_error),2))\n",
    "print('Root Mean Squared Log Error', round(np.sqrt(rmlse),2))\n",
    "print('R squared training',round(r2_train,3))\n",
    "print('R squared testing',round(r2_test,3))\n",
    "print('Adjusted-R squared training', round(adj_r2_train,3))\n",
    "print('Adjusted-R squared testing', round(adj_r2_test,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum number of features: 22 (all features: 27)\n",
      "Score with 22 features: 0.754436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error 48171779383.76\n",
      "Root Mean Squared Error 219480.7\n",
      "Root Mean Squared Log Error 0.31\n",
      "R squared training 0.652\n",
      "R squared testing 0.627\n",
      "Adjusted-R squared training 0.652\n",
      "Adjusted-R squared testing 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# features1 = [\"grade\",\"sqft_living15\"]\n",
    "features1 = feature_selection2.select_features_RFE(X_train, X_valid, y_train, y_valid)\n",
    "\n",
    "# clf = SVR(C=1.0, epsilon=0.1, kernel='linear', gamma='auto')\n",
    "clf = LinearSVR(tol=1e-4, loss='squared_epsilon_insensitive')\n",
    "X_my_train = X_train[features1]#.values.reshape(-1,1)\n",
    "X_my_valid = X_valid[features1]#.values.reshape(-1,1)\n",
    "# clf = SVR(C=1.0, epsilon=0.1)\n",
    "clf.fit(X_my_train, y_train)\n",
    "\n",
    "y_hat = clf.predict(X_my_valid)\n",
    "mean_squared_error=metrics.mean_squared_error(inv_boxcox(y_valid, price_lambda),inv_boxcox(y_hat, price_lambda))\n",
    "rmlse = metrics.mean_squared_log_error(inv_boxcox(y_valid, price_lambda), inv_boxcox(y_hat, price_lambda))\n",
    "\n",
    "r2_train = clf.score(X_my_train, y_train)\n",
    "r2_test = clf.score(X_my_valid, y_valid)\n",
    "adj_r2_train = 1 - (((1 - r2_train) * (X_my_train.shape[0] - 1)) / (X_my_train.shape[0] - X_my_train.shape[1] - 1))\n",
    "adj_r2_test = 1 - (((1 - r2_test) * (X_my_valid.shape[0] - 1)) / (X_my_valid.shape[0] - X_my_valid.shape[1] - 1))\n",
    "\n",
    "print('Mean Squared Error', round(mean_squared_error, 2))\n",
    "print('Root Mean Squared Error', round(np.sqrt(mean_squared_error),2))\n",
    "print('Root Mean Squared Log Error', round(np.sqrt(rmlse),2))\n",
    "print('R squared training',round(r2_train,3))\n",
    "print('R squared testing',round(r2_test,3))\n",
    "print('Adjusted-R squared training', round(adj_r2_train,3))\n",
    "print('Adjusted-R squared testing', round(adj_r2_test,3))\n",
    "\n",
    "\n",
    "# plt.scatter(X_my_valid, y_valid, color = 'magenta')\n",
    "# plt.plot(X_my_valid, clf.predict(X_my_valid), color = 'green')\n",
    "# plt.title('Truth or Bluff (Support Vector Regression Model)')\n",
    "# plt.xlabel('Grade')\n",
    "# plt.ylabel('Price')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD + Nystroem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum number of features: 22 (all features: 27)\n",
      "Score with 22 features: 0.754436\n",
      "Mean Squared Error 120493650338.01\n",
      "Root Mean Squared Error 347121.95\n",
      "Root Mean Squared Log Error 0.56\n",
      "R squared training -0.221\n",
      "R squared testing -0.192\n",
      "Adjusted-R squared training -0.223\n",
      "Adjusted-R squared testing -0.198\n"
     ]
    }
   ],
   "source": [
    "features1 = feature_selection2.select_features_RFE(X_train, X_valid, y_train, y_valid)\n",
    "\n",
    "clf = SGDRegressor(tol=1e-3, penalty='l1', shuffle=False)\n",
    "feature_map_nystroem = Nystroem(gamma=.2, random_state=1, n_components=300)\n",
    "\n",
    "data_transformed_train = feature_map_nystroem.fit_transform(X_train[features1])\n",
    "data_transformed_valid = feature_map_nystroem.transform(X_valid[features1])\n",
    "\n",
    "clf.fit(data_transformed_train, np.ravel(y_train))\n",
    "y_hat = clf.predict(data_transformed_valid)\n",
    "\n",
    "mean_squared_error=metrics.mean_squared_error(inv_boxcox(y_valid, price_lambda),inv_boxcox(y_hat, price_lambda))\n",
    "rmlse = metrics.mean_squared_log_error(inv_boxcox(y_valid, price_lambda), inv_boxcox(y_hat, price_lambda))\n",
    "\n",
    "r2_train = clf.score(data_transformed_train, y_train)\n",
    "r2_test = clf.score(data_transformed_valid, y_valid)\n",
    "adj_r2_train = 1 - (((1 - r2_train) * (X_train.shape[0] - 1)) / (X_train.shape[0] - X_train[features1].shape[1] - 1))\n",
    "adj_r2_test = 1 - (((1 - r2_test) * (X_valid.shape[0] - 1)) / (X_valid.shape[0] - X_valid[features1].shape[1] - 1))\n",
    "\n",
    "print('Mean Squared Error', round(mean_squared_error, 2))\n",
    "print('Root Mean Squared Error', round(np.sqrt(mean_squared_error),2))\n",
    "print('Root Mean Squared Log Error', round(np.sqrt(rmlse),2))\n",
    "print('R squared training',round(r2_train,3))\n",
    "print('R squared testing',round(r2_test,3))\n",
    "print('Adjusted-R squared training', round(adj_r2_train,3))\n",
    "print('Adjusted-R squared testing', round(adj_r2_test,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD + RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum number of features: 22 (all features: 27)\n",
      "Score with 22 features: 0.754436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-37f03f082085>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[0mfeatures1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_selection2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_features_RFE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m \u001b[0mdf_results2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[0mdf_results2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-185-37f03f082085>\u001b[0m in \u001b[0;36mrandom_search\u001b[1;34m(param_grid, max_iterations, features)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mhyperparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0meval_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meval_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mdf_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-185-37f03f082085>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(hyperparameters, iteration, features1)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_transformed_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minv_boxcox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprice_lambda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minv_boxcox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprice_lambda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mrmlse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_log_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minv_boxcox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprice_lambda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minv_boxcox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprice_lambda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    239\u001b[0m     \"\"\"\n\u001b[0;32m    240\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 241\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    242\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 542\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "def objective(hyperparameters, iteration, features1):\n",
    "\n",
    "    clf = SGDRegressor(**hyperparameters)\n",
    "    feature_map_nystroem = Nystroem(gamma=.2, random_state=1, n_components=300)\n",
    "    data_transformed_train = feature_map_nystroem.fit_transform(X_train[features1])\n",
    "    data_transformed_valid = feature_map_nystroem.transform(X_valid[features1])\n",
    "\n",
    "    clf.fit(data_transformed_train, np.ravel(y_train))\n",
    "\n",
    "    y_hat = clf.predict(data_transformed_valid)\n",
    "    \n",
    "    mean_squared_error=metrics.mean_squared_error(inv_boxcox(y_valid, price_lambda),inv_boxcox(y_hat, price_lambda))\n",
    "    rmlse = metrics.mean_squared_log_error(inv_boxcox(y_valid, price_lambda), inv_boxcox(y_hat, price_lambda))\n",
    "\n",
    "    r2_train = clf.score(data_transformed_train, y_train)\n",
    "    r2_test = clf.score(data_transformed_valid, y_valid)\n",
    "    adj_r2_train = 1 - (((1 - r2_train) * (X_my_train.shape[0] - 1)) / (X_my_train.shape[0] - X_my_train[features1].shape[1] - 1))\n",
    "    adj_r2_test = 1 - (((1 - r2_test) * (X_my_valid.shape[0] - 1)) / (X_my_valid.shape[0] - X_my_valid[features1].shape[1] - 1))\n",
    "    \n",
    "    score = {\n",
    "        \"MSE\": round(mean_squared_error, 2),\n",
    "        \"RMSE\": round(np.sqrt(mean_squared_error),2),\n",
    "        \"RMSLE\": round(np.sqrt(rmlse),2),\n",
    "        \"R2_train\": round(r2_train,3),\n",
    "        \"R2_test\": round(r2_test,3),\n",
    "        \"Adj_R2_train\": round(adj_r2_train,3),\n",
    "        \"Adj_R2_test\": round(adj_r2_test,3)\n",
    "    }\n",
    "    \n",
    "    return [score, hyperparameters]\n",
    "\n",
    "\n",
    "def random_search(param_grid, max_iterations, features):\n",
    "    \n",
    "    df_results = pd.DataFrame(columns = ['MSE', 'RMSE', 'RMSLE', 'R2_train', 'R2_test', 'Adj_R2_train', 'Adj_R2_test', 'params'],\n",
    "                                  index = list(range(max_iterations)))\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        hyperparameters = {k: random.choice(v) for k, v in param_grid.items()}\n",
    "        \n",
    "        eval_results = objective(hyperparameters, i, features)\n",
    "        for k,v in eval_results[0].items():\n",
    "            df_results[k][i] = v\n",
    "        df_results['params'][i] = eval_results[1]\n",
    "    \n",
    "    # Sort with best score on top\n",
    "    df_results.sort_values('R2_test', ascending = False, inplace = True)\n",
    "    df_results.reset_index(inplace=True)\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': np.random.uniform(1e-5,1e-3,100),\n",
    "#     'average': [True,False],\n",
    "#     'early_stopping': [True],\n",
    "#     'epsilon': [0.1],\n",
    "#     'eta0': np.random.uniform(0.001,0.1,100),\n",
    "#     'fit_intercept': [True],\n",
    "    'l1_ratio': np.random.uniform(0.1,0.9,100),\n",
    "    'learning_rate': ['constant','optimal', 'adaptive','invscaling'],\n",
    "    'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    'max_iter': [10000],\n",
    "    'n_iter_no_change': [5],\n",
    "    'penalty': ['l1','l2','elasticnet'],\n",
    "    'power_t': np.random.uniform(0.15,0.4,100),\n",
    "    'shuffle': [False],\n",
    "    \"tol\":np.random.uniform(1e-4, 1e-2, 100),\n",
    "    'validation_fraction': np.arange(0.1, 0.3, 0.05),\n",
    "}\n",
    "\n",
    "random.seed(50)\n",
    "features1 = feature_selection2.select_features_RFE(X_train, X_valid, y_train, y_valid)\n",
    "df_results2 = random_search(param_grid, 50, features1)\n",
    "df_results2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
